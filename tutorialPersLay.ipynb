{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A tutorial for \n",
    "\n",
    "# *PersLay: A Simple and Versatile Neural Network Layer for Persistence Diagrams*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ Theo Lacombe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ This is an alpha version of PersLay. Do not hesitate to contact the authors for any comment, suggestion, bug, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the current version of Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"Current version of your system: (we recommand Python 3.6)\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate, visualization, load\n",
    "from archi import perslay, baseModel\n",
    "from preprocessing import preprocess\n",
    "from expe import single_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline:\n",
    "In this notebook:\n",
    "- First, we select a dataset. Two types of datasets are provided by default, either synthetic orbits from dynamical systems, or real-life graph dataset. \n",
    "- Then, we generate the persistence diagrams (and other useful informations such as labels, etc.) for the chosen dataset.\n",
    "- (Optional) we propose to visualize the generated diagrams.\n",
    "- We define a neural network that uses some PersLay channels as first layers to handle persistence diagrams. This can be used as a guideline to use PersLay in your own experiments.\n",
    "- We show how to train this neural network on the chosen dataset.\n",
    "- Finally, we explain how you could use PersLay with your own persistence diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Building diagrams and eventual features from a provided dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ If you want to use PersLay with your own diagrams, skip this section and jump to 1bis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by choosing the dataset we want to run the experiments on.\n",
    "\n",
    "We suggest the user to start with `\"MUTAG\"` as this dataset is reasonably small (188 graphs with 18 nodes on average). Note that its small size implies a large variability in tests.\n",
    "\n",
    "Available options are:\n",
    "\n",
    "- Orbit datasets: `\"ORBIT5K\"`, `\"ORBIT100K\"`.\n",
    "\n",
    "- Graphs datasets: `\"MUTAG\"`, `\"BZR\"`, `\"COX2\"`, `\"DHFR\"`, `\"PROTEINS\"`, `\"NCI1\"`, `\"NCI109\"`, `\"FRANKENSTEIN\"`,  `\"IMDB-BINARY\"`, `\"IMDB-MULTI\"`.\n",
    "\n",
    "__Important note:__ `COLLAB`, `\"REDDIT5K\"` and `\"REDDIT12K\"` are not available yet (see README.md). Contact the authors for more information.\n",
    "\n",
    "Beware that for the larger datasets (`COLLAB`, `REDDIT5K, REDDIT12K, ORBIT100K`), the needed files can be quite large (e.g. 3Gb for for `ORBIT100K`), so that RAM can be limiting, and time to generate the diagrams and running the experiments can be quite involving depending on the hardware available. You can have access to a description of the dataset in the Section B in the supplementary material of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose your config file using one of the filename mentioned above.\n",
    "dataset = \"MUTAG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we implicitely load our data (saved as `.mat` files for graphs datasets, and generated on-the-fly for orbits datasets---which can take some time for `ORBIT100K` especially), and then compute the persistence diagrams that will be used in the classification experiment (requires to have `gudhi` installed). For graph datasets, we also generate a series of additional features (see [1]).\n",
    "\n",
    "Running `generate` will store diagrams, features and labels. Therefore, it is sufficient to run it just once (for each different dataset).\n",
    "\n",
    "Note that for bigger datasets, the computations of these diagrams can be quite long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load and preprocess diagrams (to make them PersLay-compatible) and other useful items using the files that we have generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats, diags_tmp, filts, labels = load(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to visualise some example of diagrams generated.\n",
    "# Requires matplotlib.\n",
    "visualization(diags_tmp, filts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we preprocess our diagrams to make them PersLay-compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diags = preprocess(diags_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1bis. Alternative: use your own diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ Skip this section if you want to use the diagrams generated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a (hopefully) convenient way to use your own diagrams for a classification task (with some eventual features).\n",
    "\n",
    "Diagrams must be given in the following format:\n",
    "Assume you have $N$ observations. For each of them, you build $K$ different diagrams (e.g. diagrams in different homology dimensions, for different filtration, etc.). \n",
    "\n",
    "Then, you must provide a `diags_tmp` variable that is a `dictionnary`, whose $K$ keys are the diagram type names (e.g. `Rips_dim_0`, `Cech_dim_1`). For each key $k_i$, $1 \\leq i \\leq K$, the corresponding value is a `list` of `np.arrays`, each array encoding a diagram. \n",
    "\n",
    "Note that each lists must have the same length $N$ (you need to have the same number of diagrams generated for each list). Note also that you must keep the order (i.e. the first element of each list must correspond to the diagrams generated with the first observation, and so on).\n",
    "\n",
    "Below is an example of such a (very simple) dictionnary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# diags_tmp = {'Alpha0':[np.array([[0.1, 0.2], \n",
    "#                                 [0.2, 0.5],\n",
    "#                                 [0.3, 0.9]]),  # a first dgm with 3 pts\n",
    "#                       np.array([[0.1, 0.4], \n",
    "#                                 [0.3, 0.5]]),  # a second dgm with 2 pts\n",
    "#                      ],  # end of the first diagram type\n",
    "#            'Alpha1':[np.array([[0.1, 0.4], \n",
    "#                                 [0.2, 0.6],\n",
    "#                                 [0.4, 0.9]]),\n",
    "#                       np.array([[0.1, 0.2], \n",
    "#                                 [0.5, 0.7],\n",
    "#                                 [0.8, 0.9]]),\n",
    "#                      ]  # end of the second diagram type\n",
    "#            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To use your own diagrams, uncomment and complete the following\n",
    "# diags_tmp = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we apply a preprocessing that makes our sets of diagrams compatible with perslay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Uncomment the following to process your diagrams (necessary)\n",
    "# diags = preprocess(diags_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you must (obviously) provide the labels corresponding to each diagrams (be careful that you keep the same order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To use your own labels, uncomment and complete the following\n",
    "# labels = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use some additional \"standard\" features in your network. These features must be provided as a $N \\times d$ `np.array`, where $N$ is your number of observation (as before) and $d$ the dimension of your features.\n",
    "\n",
    "If you do not want to use additional features, you must use an empty array of size $(N,0)$, where $N$ is the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment and complete the following line to not use feat.\n",
    "# N = ...   # number of observations\n",
    "# feats = np.array([[]]*N)\n",
    "### To use your own features instead, uncomment and complete the following\n",
    "# feats = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using PersLay in a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a PersLay layer, and then a (very simple) neural network architecture that uses PersLay. This can be used as a template to build your own architecture using PersLay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Set the hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer type, must be one of (see [1] for details):\n",
    "- `\"im\"` for persistence image layer.\n",
    "- `\"pm\"` for permutation equivarient layer (as in [2]).\n",
    "- `\"gs\"` for a gaussian layer.\n",
    "- `\"ls\"` for a landscape layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_type = \"im\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choice of the weight function, either:\n",
    "- `\"linear\"`\n",
    "- `\"grid\"`, in this case the user must pick a grid size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = \"grid\"\n",
    "grid_size = [10,10]  # only useful if weight==\"grid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation invariant operator, must be one of:\n",
    "- `\"sum\"`.\n",
    "- `\"topk\"`, will select the $k$ highest values, specified in `keep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_op = \"sum\"\n",
    "keep = 5  # only useful if perm_op = \"topk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there are some hyper parameters that are specific to different the layer types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter specific to layer_type=\"im\"\n",
    "image_size=[10, 10]\n",
    "# Parameter specific to layer_type=\"gs\"\n",
    "num_gaussians=50\n",
    "# Parameter specific to layer_type=\"pm\"\n",
    "d = 50  # Output dimension\n",
    "# Parameter specific to layer_type=\"ls\"\n",
    "num_samples = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we concatenate all these parameters in a dictionnary that will be given to our model (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perslayParameters = {\"layer_type\":layer_type,\n",
    "                     \"perm_op\": perm_op, \"keep\":keep,\n",
    "                     \"weight\":weight, \"grid_size\":grid_size,\n",
    "                     \"image_size\": image_size,\n",
    "                     \"num_gaussians\": num_gaussians,\n",
    "                     \"pm_dimension\": d,\n",
    "                     \"num_samples\": num_samples}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ There are some other parameters available to tune PersLay that are not detailed here. This will be updated later. Feel free to check the implementation provided in `archi.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Designing the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the template below, we define a very simple `baseModel` that encodes a network architecture. In this model, we define a PersLay layer for each type of diagrams used in input, but all these layers have the same hyper-parameters (as in [1]).\n",
    "\n",
    "Eventual additional features are simply concatenated with the output of these perslay layers, and a fully connected layer is then used to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = baseModel(perslayParameters, filts, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As any neural-network framework, PersLay benefits from the use of GPU(s). If a GPU is available (and `tensorflow-gpu` is installed), the computations should hopefully use it. Otherwise, the computations will be run on the cpu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suggest the user to run a single-run first with the `single_run` function, that is training the network once and observing the performance (classification accuracy) on the test set.\n",
    "- For orbit datasets, we suggest to use a 70-30 train-test split (to be consistent with [LY18]), i.e. `test_size = 0.3`.\n",
    "- For graph datasets, we suggest to use a 90-10 train-test split (to be consistent with [ZWX+18]), i.e. `test_size = 0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `single_run` function will load (and print) the network parameters as described in Table 5<CHECK LABEL>: perslay hyperparameters (choice of $\\phi$, $w$...), optimizer (number of epochs, learning rate...), etc.\n",
    "   \n",
    "It then uses the diagrams (and eventual features) that have been generated when calling `generate(dataset)`, randomly split them into train/test sets, and use them to feed to the network. \n",
    "\n",
    "Train and Test accuracies are printed every 10 epochs during the training.\n",
    "\n",
    "Note that (especially on small datasets like `MUTAG, COX2` etc.), there can be an important variability in the accuracy reported on different calls of `single_run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify optimization parameters.\n",
    "decay = 0.9\n",
    "lr = 0.01\n",
    "num_epoch = 100\n",
    "optim_parameters = {\"decay\":decay,\"lr\":lr, \"num_epoch\":num_epoch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "single_run(diags, feats, labels, filts, model, optim_parameters, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] _PersLay: A Simple and Versatile Neural Network Layer for Persistence Diagrams._\n",
    "Mathieu Carrière, Frederic Chazal, Yuichi Ike, Théo Lacombe, Martin Royer, Yuhei Umeda.\n",
    "\n",
    "[2] _Deep Sets._\n",
    "Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan R. Salakhutdinov, Alexander J. Smola.\n",
    "_Advances in Neural Information Processing Systems 30 (NIPS 2017)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
