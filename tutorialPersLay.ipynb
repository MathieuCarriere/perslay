{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A tutorial for \n",
    "\n",
    "# *PersLay: A Simple and Versatile Neural Network Layer for Persistence Diagrams*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ This is an alpha version of PersLay. Do not hesitate to contact the authors for any comment, suggestion, bug, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the current version of Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current version of your system: (we recommand Python 3.6)\n",
      "3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Current version of your system: (we recommand Python 3.6)\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate, visualization, load\n",
    "from archi import perslay, baseModel\n",
    "from preprocessing import preprocess\n",
    "from expe import single_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline:\n",
    "In this notebook:\n",
    "- First, we select a dataset. Two types of datasets are provided by default, either synthetic orbits from dynamical systems, or real-life graph dataset. \n",
    "- Then, we generate the persistence diagrams (and other useful informations such as labels, etc.) for the chosen dataset.\n",
    "- (Optional) we propose to visualize the generated diagrams.\n",
    "- We define a neural network that uses some PersLay channels as first layers to handle persistence diagrams. This can be used as a guideline to use PersLay in your own experiments.\n",
    "- We show how to train this neural network on the chosen dataset.\n",
    "- Finally, we explain how you could use PersLay with your own persistence diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Building diagrams and eventual features from a provided dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by choosing the dataset we want to run the experiments on.\n",
    "\n",
    "We suggest the user to start with `\"MUTAG\"` as this dataset is reasonably small (188 graphs with 18 nodes on average). Note that its small size implies a large variability in tests.\n",
    "\n",
    "Available options are:\n",
    "\n",
    "- Orbit datasets: `\"ORBIT5K\"`, `\"ORBIT100K\"`.\n",
    "\n",
    "- Graphs datasets: `\"MUTAG\"`, `\"BZR\"`, `\"COX2\"`, `\"DHFR\"`, `\"PROTEINS\"`, `\"NCI1\"`, `\"NCI109\"`, `\"FRANKENSTEIN\"`,  `\"IMDB-BINARY\"`, `\"IMDB-MULTI\"`.\n",
    "\n",
    "__Important note:__ `COLLAB`, `\"REDDIT5K\"` and `\"REDDIT12K\"` are not available yet (see README.md). Contact the authors for more information.\n",
    "\n",
    "Beware that for the larger datasets (`COLLAB`, `REDDIT5K, REDDIT12K, ORBIT100K`), the needed files can be quite large (e.g. 3Gb for for `ORBIT100K`), so that RAM can be limiting, and time to generate the diagrams and running the experiments can be quite involving depending on the hardware available. You can have access to a description of the dataset in the Section B in the supplementary material of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose your config file using one of the filename mentioned above.\n",
    "dataset = \"MUTAG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we implicitely load our data (saved as `.mat` files for graphs datasets, and generated on-the-fly for orbits datasets---which can take some time for `ORBIT100K` especially), and then compute the persistence diagrams that will be used in the classification experiment (requires to have `gudhi` installed). For graph datasets, we also generate a series of additional features (see [1]).\n",
    "\n",
    "Running `generate` will store diagrams, features and labels. Therefore, it is sufficient to run it just once (for each different dataset).\n",
    "\n",
    "Note that for bigger datasets, the computations of these diagrams can be quite long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load and preprocess diagrams (to make them PersLay-compatible) and other useful items using the files that we have generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats, diags_tmp, filts, labels = load(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 24 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to visualise some example of diagrams generated.\n",
    "# Requires matplotlib.\n",
    "visualization(diags_tmp, filts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we preprocess our diagrams to make them PersLay-compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diags = preprocess(diags_tmp, filts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46680657, 0.64623223, 1.        ],\n",
       "       [0.30371392, 0.5962502 , 1.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diags[1][56]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1bis. Alternative: use your own diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip this section if you want to use the diagrams generated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using PersLay in a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a PersLay layer, and then a (very simple) neural network architecture that uses PersLay. This can be used as a template to build your own architecture using PersLay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Set the hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer type, must be one of (see [1] for details):\n",
    "- `\"im\"` for persistence image layer.\n",
    "- `\"pm\"` for permutation equivarient layer (as in [2]).\n",
    "- `\"gs\"` for a gaussian layer.\n",
    "- `\"ls\"` for a landscape layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_type = \"im\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation invariant operator, must be one of:\n",
    "- `\"sum\"`.\n",
    "- `\"topk\"`, will select the $k$ highest values, specified in `keep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_op = \"sum\"\n",
    "keep = 5  # only useful if perm_op = \"topk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight, must be one of\n",
    "- `\"grid\"`, if so, one must pick a grid_size.\n",
    "- `\"linear\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=\"grid\"\n",
    "grid_size = [10, 10]  # Only used if weight==\"grid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there are some hyper parameters that are specific to different the layer types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter specific to layer_type=\"im\"\n",
    "image_size=[10, 10]\n",
    "# Parameter specific to layer_type=\"gs\"\n",
    "num_gaussians=50\n",
    "# Parameter specific to layer_type=\"pm\"\n",
    "d = 50  # Output dimension\n",
    "# Parameter specific to layer_type=\"ls\"\n",
    "num_samples = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we concatenate all these parameters in a dictionnary that will be given to our model (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "perslayParameters = {\"layer_type\":layer_type, \n",
    "                     \"perm_op\": perm_op, \"keep\":keep, \n",
    "                     \"weight\":weight, \"grid_size\": grid_size, \n",
    "                    \"image_size\": image_size,\n",
    "                    \"num_gaussians\": num_gaussians,\n",
    "                    \"pm_dimension\": d,\n",
    "                    \"num_samples\": num_samples}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ There are some other parameters available to tune PersLay that are not detailed here. This will be updated later. Feel free to check the implementation provided in `archi.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Designing the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the template below, we define a very simple `baseModel` that encodes a network architecture. In this model, we define a PersLay layer for each type of diagrams used in input, but all these layers have the same hyper-parameters (as in [1]).\n",
    "\n",
    "Eventual additional features are simply concatenated with the output of these perslay layers, and a fully connected layer is then used to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = baseModel(perslayParameters, filts, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As any neural-network framework, PersLay benefits from the use of GPU(s). If a GPU is available (and `tensorflow-gpu` is installed), the computations should hopefully use it. Otherwise, the computations will be run on the cpu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suggest the user to run a single-run first with the `single_run` function, that is training the network once and observing the performance (classification accuracy) on the test set.\n",
    "- For orbit datasets, the train-test split is 70-30 (to be consistent with [LY18]).\n",
    "- For graph datasets, the train-test split is 90-10 (to be consistent with [ZWX+18]).\n",
    "\n",
    "The `single_run` function will load (and print) the network parameters as described in Table 5<CHECK LABEL>: perslay hyperparameters (choice of $\\phi$, $w$...), optimizer (number of epochs, learning rate...), etc.\n",
    "   \n",
    "It then uses the diagrams (and eventual features) that have been generated when calling `generate(dataset)`, randomly split them into train/test sets, and use them to feed to the network. \n",
    "\n",
    "Train and Test accuracies are printed every 10 epochs during the training.\n",
    "\n",
    "Note that (especially on small datasets like `MUTAG, COX2` etc.), there can be an important variability in the accuracy reported on different calls of `single_run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing a Single Run on the dataset: MUTAG with a 90-10 split.\n",
      "Filtrations used:\n",
      "['10.0-hks']\n",
      "Thresholding in diagrams: 1000\n",
      " ***** PersLay parameters: *****\n",
      "Layer type: im\n",
      "image size: [20, 20]\n",
      "grid size: [20, 20]\n",
      "***** Optimization parameters *****\n",
      "Optimizer: adam\n",
      "Number of epochs: 100\n",
      "Learning rate: 0.01\n",
      "Decay: 0.9\n",
      "********************\n",
      "169 train points and 19 test points\n",
      "WARNING:tensorflow:From /home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "current indices\n",
      "[<tf.Tensor 'tower_0/perslay-0-grid_pweight/Cast:0' shape=(?, 1, 1) dtype=int32>]\n",
      "Tensor(\"tower_0/perslay-0-grid_pweight/concat:0\", shape=(?, 1, 1), dtype=int32, device=/device:GPU:0)\n",
      "current W\n",
      "<tf.Variable 'perslay-0-grid_pweight/W:0' shape=(10, 10) dtype=float32_ref>\n",
      "current indices\n",
      "[<tf.Tensor 'tower_0/perslay-0-grid_pweight/Cast:0' shape=(?, 1, 1) dtype=int32>, <tf.Tensor 'tower_0/perslay-0-grid_pweight/Cast_1:0' shape=(?, 1, 1) dtype=int32>]\n",
      "Tensor(\"tower_0/perslay-0-grid_pweight/concat_1:0\", shape=(?, 1, 2), dtype=int32, device=/device:GPU:0)\n",
      "current W\n",
      "<tf.Variable 'perslay-0-grid_pweight/W:0' shape=(10, 10) dtype=float32_ref>\n",
      "WARNING:tensorflow:From /home/theo/Git/perslay/archi.py:172: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "current indices\n",
      "[<tf.Tensor 'tower_0/perslay-1-grid_pweight/Cast:0' shape=(?, 7, 1) dtype=int32>]\n",
      "Tensor(\"tower_0/perslay-1-grid_pweight/concat:0\", shape=(?, 7, 1), dtype=int32, device=/device:GPU:0)\n",
      "current W\n",
      "<tf.Variable 'perslay-1-grid_pweight/W:0' shape=(10, 10) dtype=float32_ref>\n",
      "current indices\n",
      "[<tf.Tensor 'tower_0/perslay-1-grid_pweight/Cast:0' shape=(?, 7, 1) dtype=int32>, <tf.Tensor 'tower_0/perslay-1-grid_pweight/Cast_1:0' shape=(?, 7, 1) dtype=int32>]\n",
      "Tensor(\"tower_0/perslay-1-grid_pweight/concat_1:0\", shape=(?, 7, 2), dtype=int32, device=/device:GPU:0)\n",
      "current W\n",
      "<tf.Variable 'perslay-1-grid_pweight/W:0' shape=(10, 10) dtype=float32_ref>\n",
      "current indices\n",
      "[<tf.Tensor 'tower_0/perslay-2-grid_pweight/Cast:0' shape=(?, 13, 1) dtype=int32>]\n",
      "Tensor(\"tower_0/perslay-2-grid_pweight/concat:0\", shape=(?, 13, 1), dtype=int32, device=/device:GPU:0)\n",
      "current W\n",
      "<tf.Variable 'perslay-2-grid_pweight/W:0' shape=(10, 10) dtype=float32_ref>\n",
      "current indices\n",
      "[<tf.Tensor 'tower_0/perslay-2-grid_pweight/Cast:0' shape=(?, 13, 1) dtype=int32>, <tf.Tensor 'tower_0/perslay-2-grid_pweight/Cast_1:0' shape=(?, 13, 1) dtype=int32>]\n",
      "Tensor(\"tower_0/perslay-2-grid_pweight/concat_1:0\", shape=(?, 13, 2), dtype=int32, device=/device:GPU:0)\n",
      "current W\n",
      "<tf.Variable 'perslay-2-grid_pweight/W:0' shape=(10, 10) dtype=float32_ref>\n",
      "current indices\n",
      "[<tf.Tensor 'tower_0/perslay-3-grid_pweight/Cast:0' shape=(?, 6, 1) dtype=int32>]\n",
      "Tensor(\"tower_0/perslay-3-grid_pweight/concat:0\", shape=(?, 6, 1), dtype=int32, device=/device:GPU:0)\n",
      "current W\n",
      "<tf.Variable 'perslay-3-grid_pweight/W:0' shape=(10, 10) dtype=float32_ref>\n",
      "current indices\n",
      "[<tf.Tensor 'tower_0/perslay-3-grid_pweight/Cast:0' shape=(?, 6, 1) dtype=int32>, <tf.Tensor 'tower_0/perslay-3-grid_pweight/Cast_1:0' shape=(?, 6, 1) dtype=int32>]\n",
      "Tensor(\"tower_0/perslay-3-grid_pweight/concat_1:0\", shape=(?, 6, 2), dtype=int32, device=/device:GPU:0)\n",
      "current W\n",
      "<tf.Variable 'perslay-3-grid_pweight/W:0' shape=(10, 10) dtype=float32_ref>\n",
      "WARNING:tensorflow:From /home/theo/Git/perslay/archi.py:207: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From /home/theo/Git/perslay/archi.py:213: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[68,0] = [10, 1] does not index into param shape [10,10]\n\t [[node tower_0/perslay-0-grid_pweight/GatherNd (defined at /home/theo/Git/perslay/archi.py:77) ]]\n\nCaused by op 'tower_0/perslay-0-grid_pweight/GatherNd', defined at:\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 378, in dispatch_queue\n    yield self.process_one()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3220, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-809927c2500c>\", line 1, in <module>\n    single_run(dataset, model)\n  File \"/home/theo/Git/perslay/expe.py\", line 400, in single_run\n    decay, learn_rate, batch_size, verbose)\n  File \"/home/theo/Git/perslay/expe.py\", line 61, in _evaluate_nn_model\n    tow_logit = model.instance(tow_indxs, tow_feats, tow_diags)\n  File \"/home/theo/Git/perslay/archi.py\", line 201, in instance\n    peq=[(self.parameters[\"pm_dimension\"], None)]\n  File \"/home/theo/Git/perslay/archi.py\", line 77, in perslay\n    weight = tf.expand_dims(tf.gather_nd(params=W, indices=tf.concat(indices, axis=2)), -1)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3647, in gather_nd\n    \"GatherNd\", params=params, indices=indices, name=name)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[68,0] = [10, 1] does not index into param shape [10,10]\n\t [[node tower_0/perslay-0-grid_pweight/GatherNd (defined at /home/theo/Git/perslay/archi.py:77) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[68,0] = [10, 1] does not index into param shape [10,10]\n\t [[{{node tower_0/perslay-0-grid_pweight/GatherNd}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-809927c2500c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msingle_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Git/perslay/expe.py\u001b[0m in \u001b[0;36msingle_run\u001b[0;34m(dataset, model)\u001b[0m\n\u001b[1;32m    398\u001b[0m         ltrain, lvalid, ltest = _evaluate_nn_model(labels, feats, diags, train_sub, valid_sub, test_sub,\n\u001b[1;32m    399\u001b[0m                                                    \u001b[0minstance_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtower_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m                                                    decay, learn_rate, batch_size, verbose)\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/perslay/expe.py\u001b[0m in \u001b[0;36m_evaluate_nn_model\u001b[0;34m(LB, FT, DG, train_sub, valid_sub, test_sub, model, num_tower, tower_type, num_epochs, decay, learning_rate, tower_size, verbose)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;31m# Apply gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeed_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincrease_global_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[68,0] = [10, 1] does not index into param shape [10,10]\n\t [[node tower_0/perslay-0-grid_pweight/GatherNd (defined at /home/theo/Git/perslay/archi.py:77) ]]\n\nCaused by op 'tower_0/perslay-0-grid_pweight/GatherNd', defined at:\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 378, in dispatch_queue\n    yield self.process_one()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3220, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-809927c2500c>\", line 1, in <module>\n    single_run(dataset, model)\n  File \"/home/theo/Git/perslay/expe.py\", line 400, in single_run\n    decay, learn_rate, batch_size, verbose)\n  File \"/home/theo/Git/perslay/expe.py\", line 61, in _evaluate_nn_model\n    tow_logit = model.instance(tow_indxs, tow_feats, tow_diags)\n  File \"/home/theo/Git/perslay/archi.py\", line 201, in instance\n    peq=[(self.parameters[\"pm_dimension\"], None)]\n  File \"/home/theo/Git/perslay/archi.py\", line 77, in perslay\n    weight = tf.expand_dims(tf.gather_nd(params=W, indices=tf.concat(indices, axis=2)), -1)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3647, in gather_nd\n    \"GatherNd\", params=params, indices=indices, name=name)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/theo/anaconda3/envs/tda-deepset/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[68,0] = [10, 1] does not index into param shape [10,10]\n\t [[node tower_0/perslay-0-grid_pweight/GatherNd (defined at /home/theo/Git/perslay/archi.py:77) ]]\n"
     ]
    }
   ],
   "source": [
    "single_run(dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] _PersLay: A Simple and Versatile Neural Network Layer for Persistence Diagrams._\n",
    "Mathieu Carrière, Frederic Chazal, Yuichi Ike, Théo Lacombe, Martin Royer, Yuhei Umeda.\n",
    "\n",
    "[2] _Deep Sets._\n",
    "Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan R. Salakhutdinov, Alexander J. Smola.\n",
    "_Advances in Neural Information Processing Systems 30 (NIPS 2017)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
