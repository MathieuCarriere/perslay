{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A tutorial and template for *PersLay: A Simple and Versatile Neural Network Layer for Persistence Diagrams*.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ Théo Lacombe, Mathieu Carrière"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ This is an alpha version of PersLay. Do not hesitate to contact the authors for any comment, suggestion, bug, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Outline:__\n",
    "In this notebook:\n",
    "- First, we select a dataset. Two types of datasets are provided by default, either synthetic orbits from dynamical systems, or real-life graph dataset (we also explain how you could use PersLay with your own persistence diagrams).\n",
    "- Then, we generate the persistence diagrams (and other useful informations such as labels, etc.) for the chosen dataset.\n",
    "- (Optional) we propose to visualize the generated persistence diagrams.\n",
    "- We define a neural network that uses some PersLay channels as first layers to handle persistence diagrams. This can be used as a guideline to use PersLay in your own experiments.\n",
    "- We show how to train this neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import required Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Print the current version of Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"Current version of your system: (we recommand Python 3.6)\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Import Numpy, TensorFlow, PersLay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import random_uniform_initializer as rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from perslay.perslay import perslay_channel\n",
    "from perslay.preprocessing import preprocess\n",
    "from perslay.visualisation import visualise_diag\n",
    "from perslay.experiments   import load_diagfeatlabels, generate_diag_and_features, single_run, perform_expe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# (Optional) Generate predefined persistence diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Note:__ Skip this section and go to Section 3 if you already have your own persistence diagrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We start by choosing the dataset we want to run the experiments on. We suggest the user to start with `\"MUTAG\"` as this dataset is reasonably small (188 graphs with 18 nodes on average). Note that its small size implies a large variability in tests.\n",
    "\n",
    "Available options are:\n",
    "\n",
    "- Orbit datasets: `\"ORBIT5K\"`, `\"ORBIT100K\"`.\n",
    "\n",
    "- Graphs datasets: `\"BZR\"`,`\"FRANKENSTEIN\"`,`\"MUTAG\"`,`\"COX2\"`, `\"DHFR\"`, `\"PROTEINS\"`, `\"NCI1\"`, `\"NCI109\"`,`\"IMDB-BINARY\"`, `\"IMDB-MULTI\"`.\n",
    "\n",
    "__Important note:__ `\"COLLAB\"`,`\"REDDIT5K\"` and `\"REDDIT12K\"` are not available yet (see README.md). Contact the authors for more information.\n",
    "\n",
    "Beware that for the larger datasets (`\"COLLAB\"`,`\"REDDIT5K\", \"REDDIT12K\", \"ORBIT100K\"`), the files can be quite large (e.g. 3Gb for for `\"ORBIT100K\"`), so that RAM can be limiting, and the time needed to generate the persistence diagrams and run the experiments can be quite long depending on the hardware available. Dataset descriptions are available in Section B of the supplementary material of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Chose your config file using one of the filename mentioned above.\n",
    "dataset = \"PROTEINS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here, we implicitely load our data (saved as `.mat` files for graphs datasets, and generated on-the-fly for orbits datasets---which can take some time for `\"ORBIT100K\"` especially), and then compute the persistence diagrams that will be used in the classification experiment (requires to have `gudhi` installed). For graph datasets, we also generate a series of additional features (see [1]).\n",
    "\n",
    "Running `generate_diag_and_features` will store diagrams, features and labels. Therefore, it is sufficient to run it just once (for each different dataset). Note that for bigger datasets, the computations of these persistence diagrams can be quite long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "generate_diag_and_features(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Visualize persistence diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we load and preprocess persistence diagrams (to make them PersLay-compatible) and other useful items using the files that we have generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diags_tmp, feats, labels = load_diagfeatlabels(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run the following cell to visualise some example of diagrams generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualise_diag(diags_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# (Optional) Use your own persistence diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Note:__ Skip this section and make sure to go through Section 2 if you want to use the predefined persistence diagrams that we provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We provide a (hopefully) convenient way to use your own persistence diagrams for a classification task (with some eventual features).\n",
    "\n",
    "Persistence diagrams must be given in the following format:\n",
    "assume you have $N$ observations. For each of them, you build $K$ different persistence diagrams (e.g. persistence diagrams in different homology dimensions, and/or for different filtrations, etc.). \n",
    "\n",
    "Then, you must provide a `diags_tmp` variable that is a `dictionary`, whose $K$ keys are the persistence diagram type names (e.g. `\"Rips_dim_0\"`, `\"Cech_dim_1\"`). For each key $k_i$, $1 \\leq i \\leq K$, the corresponding value is a `list` of `np.arrays`, each array encoding a persistence diagram. \n",
    "\n",
    "Note that each list must have the same length $N$ (you need to have the same number of persistence diagrams generated for each list). Note also that you must keep the order (i.e. the first element of each list must correspond to the persistence diagram generated with the first observation, and so on).\n",
    "\n",
    "Below is an example of such a (very simple) dictionary, with two filtrations and two persistence diagrams in each:\n",
    "\n",
    "`diags_tmp = {\"Alpha0\":[np.array([[0.1, 0.2], [0.2, 0.5], [0.3, 0.9]]), np.array([[0.1, 0.4], [0.3, 0.5]]),], \"Alpha1\":[np.array([[0.1, 0.4], [0.2, 0.6], [0.4, 0.9]]), np.array([[0.1, 0.2], [0.5, 0.7], [0.8, 0.9]])]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### To use your own diagrams, uncomment and complete the following\n",
    "#diags_tmp = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, we apply a preprocessing that makes our sets of persistence diagrams compatible with PersLay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sklearn_tda as tda\n",
    "\n",
    "### Uncomment the following to process your diagrams (necessary)\n",
    "thresh = 500\n",
    "\n",
    "# Whole pipeline\n",
    "tmp = Pipeline([\n",
    "        (\"Selector\",      tda.DiagramSelector(use=True, point_type=\"finite\")),\n",
    "        (\"ProminentPts\",  tda.ProminentPoints(use=True, num_pts=thresh)),\n",
    "        (\"Scaler\",        tda.DiagramScaler(use=True, scalers=[([0,1], MinMaxScaler())])),\n",
    "        (\"Padding\",       tda.Padding(use=True)),\n",
    "                ])\n",
    "prm = {filt: {\"ProminentPts__num_pts\": min(thresh, max([len(dgm) for dgm in diags_tmp[filt]]))} \n",
    "       for filt in diags_tmp.keys() if max([len(dgm) for dgm in diags_tmp[filt]]) > 0}\n",
    "\n",
    "# Apply the previous pipeline on the different filtrations.\n",
    "D = []\n",
    "for dt in prm.keys():\n",
    "    param = prm[dt]\n",
    "    tmp.set_params(**param)\n",
    "    D.append(tmp.fit_transform(diags_tmp[dt]))\n",
    "\n",
    "# For each filtration, concatenate all diagrams in a single array.\n",
    "diags = []\n",
    "for dt in range(len(prm.keys())):\n",
    "    diags.append(np.concatenate([D[dt][i][np.newaxis, :] for i in range(len(D[dt]))], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, you must (obviously) provide the labels corresponding to each persistence diagram (be careful to keep the same order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### To use your own labels, uncomment and complete the following\n",
    "#labels = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can use some additional \"standard\" features in your network. These features must be provided as a $N \\times d$ `np.array`, where $N$ is your number of observations (as before) and $d$ is the dimension of your features.\n",
    "\n",
    "If you do not want to use additional features, you must use an empty array of size $(N,0)$, where $N$ is the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Uncomment and complete the following line to not use feat.\n",
    "#N = # number of observations\n",
    "#feats = np.array([[]]*N)\n",
    "\n",
    "### To use your own features instead, uncomment and complete the following\n",
    "#feats = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Using PersLay in a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (Optional) Define your own network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In case you use your own persistence diagrams, you might want to define your own architecture with PersLay. To help you with it, in the following section we define two (very simple) neural network architectures that use PersLay. They can be used as templates to build your own architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Set the hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Filtration parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the following cell, you provide information on the filtrations used to generate the persistence diagrams. The only necessary keys to fill are `learn` (whether you want to optimize filtration values), `names` (names of your different filtrations) and `pad` (threshold value you used for padding the diagrams). Note that setting `learn` to `True`, i.e., optimizing over the filtration values, is not yet publicly available (hopefully it will be soon), so make sure `learn` is `False` for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filt_parameters = {}\n",
    "filt_parameters[\"learn\"]      = False\n",
    "filt_parameters[\"names\"]      = [f for f in diags_tmp.keys()]\n",
    "filt_parameters[\"pad\"]        = thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This cell contains code referring to libraries that are not yet available, so do not run it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if filt_parameters[\"learn\"]:\n",
    "    filt_parameters[\"homology\"]   = [[0]]\n",
    "    filt_parameters[\"thresholds\"] = [[500]]\n",
    "    filt_parameters[\"init\"]       = [[10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### PersLay parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Layer type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Initialize dictionary of parameters for PersLay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Choice of layer type, must be one of (see README.md and [1] for details):\n",
    "- `\"im\"` for a persistence image layer.\n",
    "- `\"pm\"` for a permutation equivariant layer (as in [2]).\n",
    "- `\"ex\"` for an exponential structure element layer (as in [3]).\n",
    "- `\"rt\"` for a rational structure element layer (as in [3]).\n",
    "- `\"rh\"` for a rational hat structure element layer (as in [3]).\n",
    "- `\"ls\"` for a persistence landscape layer.\n",
    "- `\"bc\"` for a Betti curve layer.\n",
    "- `\"en\"` for a persistence entropy layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"layer\"]          = \"im\"\n",
    "perslay_parameters[\"image_size\"]     = (20, 20)\n",
    "epsilon = .001\n",
    "perslay_parameters[\"image_bnds\"]     = ((0. - epsilon, 1. + epsilon), (0. - epsilon, 1. + epsilon))\n",
    "perslay_parameters[\"variance_init\"]  = rui(3.0, 3.0) \n",
    "perslay_parameters[\"variance_const\"] = False\n",
    "perslay_parameters[\"cv_layers\"]      = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"layer\"]          = \"pm\"\n",
    "perslay_parameters[\"peq\"]            = [(5, \"max\")]\n",
    "perslay_parameters[\"weight_init\"]    = rui(0.0, 1.0)\n",
    "perslay_parameters[\"weight_const\"]   = False\n",
    "perslay_parameters[\"bias_init\"]      = rui(0.0, 1.0) \n",
    "perslay_parameters[\"bias_const\"]     = False\n",
    "perslay_parameters[\"fc_layers\"]      = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"layer\"]          = \"ex\"\n",
    "perslay_parameters[\"num_elements\"]   = 25\n",
    "perslay_parameters[\"mean_init\"]      = rui(0.0, 1.0)\n",
    "perslay_parameters[\"mean_const\"]     = False\n",
    "perslay_parameters[\"variance_init\"]  = rui(3.0, 3.0) \n",
    "perslay_parameters[\"variance_const\"] = False\n",
    "perslay_parameters[\"fc_layers\"]      = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"layer\"]          = \"rt\"\n",
    "perslay_parameters[\"num_elements\"]   = 25\n",
    "perslay_parameters[\"mean_init\"]      = rui(0.0, 1.0)\n",
    "perslay_parameters[\"mean_const\"]     = False\n",
    "perslay_parameters[\"variance_init\"]  = rui(3.0, 3.0) \n",
    "perslay_parameters[\"variance_const\"] = False\n",
    "perslay_parameters[\"alpha_init\"]     = rui(3.0, 3.0) \n",
    "perslay_parameters[\"alpha_const\"]    = False\n",
    "perslay_parameters[\"fc_layers\"]      = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"layer\"]          = \"rh\"\n",
    "perslay_parameters[\"num_elements\"]   = 25\n",
    "perslay_parameters[\"mean_init\"]      = rui(0.0, 1.0)\n",
    "perslay_parameters[\"mean_const\"]     = False\n",
    "perslay_parameters[\"r_init\"]         = rui(3.0, 3.0) \n",
    "perslay_parameters[\"r_const\"]        = False\n",
    "perslay_parameters[\"q\"]              = 2\n",
    "perslay_parameters[\"fc_layers\"]      = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"layer\"]          = \"ls\"\n",
    "perslay_parameters[\"num_samples\"]    = 100\n",
    "perslay_parameters[\"sample_init\"]    = rui(0.0, 1.0) \n",
    "perslay_parameters[\"sample_const\"]   = False\n",
    "perslay_parameters[\"fc_layers\"]      = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"layer\"]          = \"bc\"\n",
    "perslay_parameters[\"theta\"]          = 10\n",
    "perslay_parameters[\"num_samples\"]    = 100\n",
    "perslay_parameters[\"sample_init\"]    = rui(0.0, 1.0) \n",
    "perslay_parameters[\"sample_const\"]   = False\n",
    "perslay_parameters[\"fc_layers\"]      = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"layer\"]          = \"en\"\n",
    "perslay_parameters[\"theta\"]          = 10\n",
    "perslay_parameters[\"num_samples\"]    = 100\n",
    "perslay_parameters[\"sample_init\"]    = rui(0.0, 1.0) \n",
    "perslay_parameters[\"sample_const\"]   = False\n",
    "perslay_parameters[\"fc_layers\"]      = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Weight function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Choice of the weight function, must be one of:\n",
    "- `\"linear\"`, for a linear weight w.r.t. the distance to the diagonal.\n",
    "- `\"grid\"`, for a piecewise-constant function defined with pixel values.\n",
    "- `\"gmix\"`, for a weight function defined as a mixture of Gaussians.\n",
    "- `None`, for a constant weight function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"persistence_weight\"]  = \"linear\"\n",
    "perslay_parameters[\"coeff_init\"]          = rui(1.0, 1.0)\n",
    "perslay_parameters[\"coeff_const\"]         = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"persistence_weight\"]  = \"grid\"\n",
    "perslay_parameters[\"grid_size\"]           = [20,20]\n",
    "epsilon = .001\n",
    "perslay_parameters[\"grid_bnds\"]           = ((0. - epsilon, 1. + epsilon), (0. - epsilon, 1. + epsilon))\n",
    "perslay_parameters[\"grid_init\"]           = rui(1.0, 1.0)\n",
    "perslay_parameters[\"grid_const\"]          = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"persistence_weight\"]  = \"gmix\"\n",
    "perslay_parameters[\"gmix_num\"]            = 3\n",
    "perslay_parameters[\"gmix_m_init\"]         = rui(0.0, 1.0)\n",
    "perslay_parameters[\"gmix_m_const\"]        = False\n",
    "perslay_parameters[\"gmix_v_init\"]         = rui(.01, .01)\n",
    "perslay_parameters[\"gmix_v_const\"]        = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"persistence_weight\"]  = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Permutation-invariant operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Choice of permutation invariant operator, must be one of:\n",
    "- `\"sum\"`.\n",
    "- `\"topk\"`, will select the $k$ highest values, specified in `keep`.\n",
    "- `\"max\"`.\n",
    "- `\"mean\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"perm_op\"] = \"sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"perm_op\"] = \"topk\"\n",
    "perslay_parameters[\"keep\"]    = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"perm_op\"] = \"max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters[\"perm_op\"] = \"mean\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Predefined layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These set of predefined parameters reproduce the usual persistence images and landscapes from the literature, as well as the DeepSet vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Persistence image layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PI_perslay_parameters                        = {}\n",
    "PI_perslay_parameters[\"layer\"]               = \"im\"\n",
    "PI_perslay_parameters[\"image_size\"]          = (10, 10)\n",
    "epsilon = .001\n",
    "PI_perslay_parameters[\"image_bnds\"]          = ((0. - epsilon, 1. + epsilon), (0. - epsilon, 1. + epsilon))\n",
    "PI_perslay_parameters[\"variance_init\"]       = rui(3.0, 3.0) \n",
    "PI_perslay_parameters[\"variance_const\"]      = False\n",
    "PI_perslay_parameters[\"cv_layers\"]           = []\n",
    "PI_perslay_parameters[\"persistence_weight\"]  = \"linear\"\n",
    "PI_perslay_parameters[\"coeff_init\"]          = rui(1.0, 1.0)\n",
    "PI_perslay_parameters[\"coeff_const\"]         = False\n",
    "PI_perslay_parameters[\"perm_op\"]             = \"sum\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Persistence landscape layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LS_perslay_parameters                        = {}\n",
    "LS_perslay_parameters[\"layer\"]               = \"ls\"\n",
    "LS_perslay_parameters[\"num_samples\"]         = 100\n",
    "LS_perslay_parameters[\"sample_init\"]         = rui(0.0, 1.0) \n",
    "LS_perslay_parameters[\"sample_const\"]        = False\n",
    "LS_perslay_parameters[\"fc_layers\"]           = []\n",
    "LS_perslay_parameters[\"persistence_weight\"]  = None\n",
    "LS_perslay_parameters[\"perm_op\"]             = \"topk\"\n",
    "LS_perslay_parameters[\"keep\"]                = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "DeepSet layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PM_perslay_parameters                           = {}\n",
    "PM_perslay_parameters[\"layer\"]                  = \"pm\"\n",
    "PM_perslay_parameters[\"peq\"]                    = [(100, \"max\")]\n",
    "PM_perslay_parameters[\"weight_init\"]            = rui(0.0, 1.0)\n",
    "PM_perslay_parameters[\"weight_const\"]           = False\n",
    "PM_perslay_parameters[\"bias_init\"]              = rui(0.0, 1.0) \n",
    "PM_perslay_parameters[\"bias_const\"]             = False\n",
    "PM_perslay_parameters[\"fc_layers\"]              = []\n",
    "PM_perslay_parameters[\"persistence_weight\"]     = \"grid\"\n",
    "PM_perslay_parameters[\"grid_size\"]              = [20,20]\n",
    "epsilon = .001\n",
    "PM_perslay_parameters[\"grid_bnds\"]              = ((0. - epsilon, 1. + epsilon), (0. - epsilon, 1. + epsilon))\n",
    "PM_perslay_parameters[\"grid_init\"]              = rui(0.0, .01)\n",
    "PM_perslay_parameters[\"grid_const\"]             = False\n",
    "PM_perslay_parameters[\"perm_op\"]                = \"sum\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Design the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the template below, we define a very simple `baseModel` that encodes a network architecture. In this model, we define a PersLay layer for each type of persistence diagrams (or filtration) used in input. This layer is a weighted average of several predefined PersLay layers if `combination` is set to `True`. Otherwise, there is one specific PersLay layer for each filtration. If you want all filtrations to share the same PersLay parameters, `perslay_parameters` must be a single dictionary containing the keys defined above. If you want filtration-specific parameters, `perslay_parameters` must be a list containing several such dictionaries. Eventual additional features are simply concatenated with the outputs of these PersLay channels, and a single fully-connected operation is then used to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class baseModel:\n",
    "\n",
    "    def __init__(self, filt_parameters, perslay_parameters, labels, combination=False): \n",
    "        self.filt_parameters = filt_parameters\n",
    "        self.perslay_parameters = perslay_parameters\n",
    "        self.num_labels = labels.shape[1]\n",
    "        self.num_filts = len(self.filt_parameters[\"names\"])\n",
    "        self.combination = combination\n",
    "        \n",
    "    def get_parameters(self):\n",
    "        return [self.filt_parameters, self.perslay_parameters, self.combination]\n",
    "\n",
    "    def instance(self, indxs, feats, diags):\n",
    "        \n",
    "        if self.filt_parameters[\"learn\"]:\n",
    "            \n",
    "            lpd = tf.load_op_library(\"persistence_diagram.so\")\n",
    "            hks = tf.load_op_library(\"hks.so\")\n",
    "            import _persistence_diagram_grad\n",
    "            import _hks_grad\n",
    "            \n",
    "            H, T = np.array(self.filt_parameters[\"homology\"]), np.array(self.filt_parameters[\"thresholds\"])\n",
    "            N, I = np.array([[self.num_filts]]), np.array(self.filt_parameters[\"init\"], dtype=np.float32)\n",
    "            cumsum = np.cumsum(np.array([0] + [thr for thr in T[:,0]]))\n",
    "            times = tf.get_variable(\"times\", initializer=I)\n",
    "            conn  = hks.heat_kernel_signature(indxs, times)\n",
    "            pdiag_array, _ = lpd.persistence_diagram(H, T, indxs, N, conn)\n",
    "            pds = tf.reshape(pdiag_array, [-1, cumsum[-1], 3])\n",
    "            pdiags  = [pds[:,cumsum[i]:cumsum[i+1],:] for i in range(self.num_filts)]\n",
    "            \n",
    "        else:\n",
    "            pdiags = diags\n",
    "            \n",
    "        list_v = []\n",
    "        \n",
    "        if self.combination:\n",
    "            \n",
    "            n_pl = len(self.perslay_parameters)\n",
    "            alpha = tf.get_variable(\"perslay_coeffs\", initializer=np.array(np.ones(n_pl), dtype=np.float32))\n",
    "                \n",
    "            for i in range(self.num_filts):\n",
    "            # A perslay channel must be defined for each type of persistence diagram. \n",
    "            # Here it is a linear combination of several pre-defined layers.\n",
    "                \n",
    "                list_dgm = []\n",
    "                for prm in range(n_pl):\n",
    "                    perslay_channel(output  =  list_dgm,              # list used to store all outputs\n",
    "                                    name    =  \"perslay-\" + str(i),   # name of this layer\n",
    "                                    diag    =  pdiags[i],             # i-th type of diagrams\n",
    "                                    **self.perslay_parameters[prm])\n",
    "            \n",
    "                list_dgm = [tf.multiply(alpha[idx], tf.layers.batch_normalization(dgm)) \n",
    "                        for idx, dgm in enumerate(list_dgm)]\n",
    "                list_v.append(tf.math.add_n(list_dgm))\n",
    "        else:\n",
    "            if type(self.perslay_parameters) is not list:\n",
    "                for i in range(self.num_filts):\n",
    "                # A perslay channel must be defined for each type of persistence diagram. \n",
    "                # Here they all have the same hyper-parameters.\n",
    "                    perslay_channel(output  =  list_v,              # list used to store all outputs\n",
    "                                    name    =  \"perslay-\" + str(i), # name of this layer\n",
    "                                    diag    =  pdiags[i],           # i-th type of diagrams\n",
    "                                    **self.perslay_parameters)\n",
    "            else:\n",
    "                for i in range(self.num_filts):\n",
    "                # A perslay channel must be defined for each type of persistence diagram. \n",
    "                # Here they all have the same hyper-parameters.\n",
    "                    perslay_channel(output  =  list_v,              # list used to store all outputs\n",
    "                                    name    =  \"perslay-\" + str(i), # name of this layer\n",
    "                                    diag    =  pdiags[i],           # i-th type of diagrams\n",
    "                                    **self.perslay_parameters[i])\n",
    "\n",
    "        # Concatenate all channels and add other features\n",
    "        with tf.variable_scope(\"perslay\"):\n",
    "            representations = tf.concat(list_v, 1)\n",
    "            representations = tf.layers.batch_normalization(representations)\n",
    "        with tf.variable_scope(\"norm_feat\"):\n",
    "            feat = tf.layers.batch_normalization(feats)\n",
    "\n",
    "        final_representations = tf.concat([representations, feat], 1)\n",
    "\n",
    "        #  Final layer to make predictions\n",
    "        with tf.variable_scope(\"final-dense\"):\n",
    "            logits = tf.layers.dense(final_representations, self.num_labels)\n",
    "\n",
    "        return representations, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = baseModel(filt_parameters, perslay_parameters, labels, combination=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In each type of experiment for training the network (with either `single_run` or `perform_expe` function, see the sections below), you can either use precomputed diagrams with a predefined architecture, in which case the code will load (and print) the network parameters as described in [1] (choice of $\\phi$, $w$...), optimizer (number of epochs, learning rate...), etc. and then use the persistence diagrams (and eventual features) that have been generated when calling `generate(dataset)` to feed the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Single run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using the `single_run` function means training the network once and observing the performance (classification accuracy) on the test set.\n",
    "- For orbit datasets, we suggest to use a 70-30 train-test split, i.e. `test_size = 0.3`.\n",
    "- For graph datasets, we suggest to use a 90-10 train-test split, i.e. `test_size = 0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Predefined persistence diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Train and test accuracies are printed every 10 epochs during training. Note that (especially on small datasets like `\"MUTAG\", \"COX2\"` etc.), there can be an important variability in the accuracy reported on different calls of `single_run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weight, times, vecs = single_run(test_size=test_size, path_dataset=\"\", dataset=\"MUTAG\", \n",
    "                                 visualize_weights_times=True,\n",
    "                                 xmin=0., xmax=1., xstep=.001, ymin=0., ymax=1., ystep=.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Custom persistence diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you use your own diagrams and architecture, you have to specify optimization parameters. As for any neural network framework, PersLay benefits from the use of GPU(s). If a GPU is available (and `tensorflow-gpu` is installed), you can use it by setting `tower_type` to `\"gpu\"` in the dictionary below. If you even have more than 1 GPU available, you can specify this number in `num_tower`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optim_parameters = {\"decay\": 0., \"learning_rate\": 0.05, \"num_epochs\": 50, \"tower_size\": 128,\n",
    "                    \"optimizer\": \"adam\", \"epsilon\": 1e-4, \"num_tower\": 1, \"tower_type\": \"cpu\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In case you just want to learn the best vectorization with PersLay, and then apply a standard classifier, run the following cell to define the standard classifiers and their parameters you want to cross-validate on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "standard_parameters = [{\"Estimator\":         [RandomForestClassifier()]},\n",
    "                       {\"Estimator\":         [SVC()],\n",
    "                        \"Estimator__kernel\": [\"linear\", \"rbf\"], \n",
    "                        \"Estimator__C\":      [0.1, 1, 10]},\n",
    "                       {\"Estimator\":         [AdaBoostClassifier()]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Perform single run. If `model` is a list containing several instances of `baseModel`, the best model among these is selected with cross validation. In that case, you can use `perslay_cv` to specify the number of folds you want to use. Note that if you want to cross validate on the standard classifiers defined above, you also have to specify `standard_cv` (the two cross validations---PersLay and standard classifiers---are independent) and set `standard_model` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weight, times = single_run(test_size=test_size, path_dataset=None, dataset=\"PROTEINS\",\n",
    "                           model=model, diags=diags, feats=feats, labels=labels, \n",
    "                           optim_parameters=optim_parameters, perslay_cv=10,\n",
    "                           standard_model=True, standard_parameters=standard_parameters, standard_cv=10,\n",
    "                           visualize_weights_times=True,\n",
    "                           gmin=.8, gmax=1.2, xmin=0., xmax=1., xstep=.001, ymin=0., ymax=1., ystep=.001\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Full experiment with several runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using the `perform_expe` function means training the network with a $K$-fold validation scheme for several runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Predefined persistence diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perform_expe(num_runs=1, path_dataset=\"\", dataset=\"MUTAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Custom persistence diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optim_parameters = {\"decay\": 0., \"learning_rate\": 0.01, \"num_epochs\": 50, \"tower_size\": 128, \n",
    "                    \"optimizer\": \"adam\", \"epsilon\": 1e-4, \"num_tower\": 1, \"tower_type\": \"cpu\",\n",
    "                    \"mode\": \"KF\", \"folds\": 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "standard_parameters = [{\"Estimator\":         [RandomForestClassifier()]},\n",
    "                       {\"Estimator\":         [SVC()],\n",
    "                        \"Estimator__kernel\": [\"linear\", \"rbf\"], \n",
    "                        \"Estimator__C\":      [0.1, 1, 10]},\n",
    "                       {\"Estimator\":         [AdaBoostClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perform_expe(num_runs=1, path_dataset=None, dataset=\"PROTEINS\",\n",
    "             model=model, diags=diags, feats=feats, labels=labels, \n",
    "             optim_parameters=optim_parameters, perslay_cv=10, \n",
    "             standard_model=True, standard_parameters=standard_parameters, standard_cv=10,\n",
    "             verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[1] _PersLay: A Simple and Versatile Neural Network Layer for Persistence Diagrams._\n",
    "Mathieu Carrière, Frederic Chazal, Yuichi Ike, Théo Lacombe, Martin Royer, Yuhei Umeda.\n",
    "\n",
    "[2] _Deep Sets._\n",
    "Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan Salakhutdinov, Alexander Smola.\n",
    "_Advances in Neural Information Processing Systems 30 (NIPS 2017)_\n",
    "\n",
    "[3] _Learning Representations of Persistence Barcodes._\n",
    "Christoph Hofer, Roland Kwitt, Marc Niethammer.\n",
    "_JMLR (2019)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
